{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Quran.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNshquLjtgTEvR/H0io9zt6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aSafarpoor/NLP/blob/HW0---make-some-text-ready/Quran.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNjUK-pIUWYU"
      },
      "source": [
        "#Start ☺"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjvdx0OvU5pj"
      },
      "source": [
        "## Question list#\n",
        "\n",
        "\n",
        "\n",
        "1.   What shoulkd we do with بسم الله الرحمن الرحیم\n",
        "2.   Output formats should change\n",
        "3.   'va' problem\n",
        "4.    khoroji 'a' 'e' 'o' etc mikhahad?\n",
        "5.    Tekrar yek ebarat dar aye dobar bashe?\n",
        "6.    chand kalame?\n",
        "7.    va ham kalamas dige?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXASrVXSUe4M"
      },
      "source": [
        "# pre file and codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeOZi-LGaRGm"
      },
      "source": [
        "just run first time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2OOoFiyVIli",
        "outputId": "4665910b-5517-49f2-ef37-d979a6ea90d9"
      },
      "source": [
        "% pip install camel_tools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting camel_tools\n",
            "  Downloading camel_tools-1.2.0.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 40 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.15.0)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.6.2)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from camel_tools) (4.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.22.2.post1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.3.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from camel_tools) (1.10.0+cu111)\n",
            "Collecting transformers>=3.0.2\n",
            "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from camel_tools) (0.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from camel_tools) (2.23.0)\n",
            "Collecting camel-kenlm\n",
            "  Downloading camel-kenlm-2020.11.2.tar.gz (250 kB)\n",
            "\u001b[K     |████████████████████████████████| 250 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->camel_tools) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (3.3.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 36.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 56.1 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (4.8.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=3.0.2->camel_tools) (21.2)\n",
            "Requirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers>=3.0.2->camel_tools) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=3.0.2->camel_tools) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->camel_tools) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->camel_tools) (2.8.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->camel_tools) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->camel_tools) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->camel_tools) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->camel_tools) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->camel_tools) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=3.0.2->camel_tools) (1.1.0)\n",
            "Building wheels for collected packages: camel-tools, camel-kenlm\n",
            "  Building wheel for camel-tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camel-tools: filename=camel_tools-1.2.0-py3-none-any.whl size=99047 sha256=da76c036b09ace2d2de5df5c563f6344fd870309399269bf7ba6cc975b7bfe1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ad/a1/e8aa569c102f0b8b3522ae515b7d0696046e4490c0ff4edb0a\n",
            "  Building wheel for camel-kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for camel-kenlm: filename=camel_kenlm-2020.11.2-cp37-cp37m-linux_x86_64.whl size=2310072 sha256=c9129b7852503a51bab4802828b650839801767626f106782d2c3df72d59d64c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/be/67/7122f437e5a4328499c80d9b4b5b6a064a3501cf24d3414087\n",
            "Successfully built camel-tools camel-kenlm\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, camel-kenlm, camel-tools\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed camel-kenlm-2020.11.2 camel-tools-1.2.0 huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kBn_3SLUBgU"
      },
      "source": [
        "Below code is from https://raw.githubusercontent.com/CAMeL-Lab/camel_tools/master/camel_tools/utils/normalize.py and added here for eddition.\n",
        "\n",
        "Eddition will be describe with comment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnmOd_sSaej9"
      },
      "source": [
        "### minimize block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELUdlDP-T8bE"
      },
      "source": [
        "#@title\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# MIT License\n",
        "#\n",
        "# Copyright 2018-2021 New York University Abu Dhabi\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "# of this software and associated documentation files (the \"Software\"), to deal\n",
        "# in the Software without restriction, including without limitation the rights\n",
        "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "# copies of the Software, and to permit persons to whom the Software is\n",
        "# furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "# SOFTWARE.\n",
        "\n",
        "\n",
        "\"\"\"This module provides functions for normalizing Arabic text.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import re\n",
        "import unicodedata\n",
        "\n",
        "from camel_tools.utils.charmap import CharMapper\n",
        "\n",
        "\n",
        "_ALEF_NORMALIZE_BW_RE = re.compile(u'[<>{|]')\n",
        "_ALEF_NORMALIZE_SAFEBW_RE = re.compile(u'[IOLM]')\n",
        "_ALEF_NORMALIZE_XMLBW_RE = re.compile(u'[IO{|]')\n",
        "_ALEF_NORMALIZE_HSB_RE = re.compile(u'[\\u0102\\u00c2\\u00c4\\u0100]')\n",
        "_ALEF_NORMALIZE_AR_RE = re.compile(u'[\\u0625\\u0623\\u0671\\u0622]')\n",
        "\n",
        "_UNICODE_CHAR_FIX = CharMapper({\n",
        "                        '\\ufdfc': 'ريال',\n",
        "                        '\\ufdfd': 'بسم الله الرحمن الرحيم',\n",
        "                    })\n",
        "\n",
        "\n",
        "def normalize_unicode(s, compatibility=True):\n",
        "    \"\"\"Normalize Unicode strings into their canonically composed form or\n",
        "    (i.e. characters that can be written as a combination of unicode characters\n",
        "    are converted to their single character form).\n",
        "\n",
        "    Note: This is essentially a call to :func:`unicodedata.normalize` with\n",
        "    form 'NFC' if **compatibility** is False or 'NFKC' if it's True.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "        compatibility (:obj:`bool`, optional): Apply compatibility\n",
        "            decomposition. Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    if compatibility:\n",
        "        fixed = _UNICODE_CHAR_FIX(s)\n",
        "        return unicodedata.normalize('NFKC', fixed)\n",
        "\n",
        "    return unicodedata.normalize('NFC', s)\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_bw(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in a Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'Y', u'y')\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_safebw(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in a Safe Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'Y', u'y')\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_xmlbw(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in a XML Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'Y', u'y')\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_hsb(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in a Habash-Soudi-Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'\\u00fd', u'y')\n",
        "\n",
        "\n",
        "def normalize_alef_maksura_ar(s):\n",
        "    \"\"\"Normalize all occurences of Alef Maksura characters to a Yeh character\n",
        "    in an Arabic string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'\\u0649', u'\\u064a')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_bw(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in a Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'p', u'h')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_safebw(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in a Safe Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'p', u'h')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_xmlbw(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in a XML Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'p', u'h')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_hsb(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in a Habash-Soudi-Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'\\u0127', u'h')\n",
        "\n",
        "\n",
        "def normalize_teh_marbuta_ar(s):\n",
        "    \"\"\"Normalize all occurences of Teh Marbuta characters to a Heh character\n",
        "    in an Arabic string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return s.replace(u'\\u0629', u'\\u0647')\n",
        "\n",
        "\n",
        "def normalize_alef_bw(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in a\n",
        "    Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_BW_RE.sub(u'A', s)\n",
        "\n",
        "\n",
        "def normalize_alef_safebw(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in a\n",
        "    Safe Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_SAFEBW_RE.sub(u'A', s)\n",
        "\n",
        "\n",
        "def normalize_alef_xmlbw(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in a\n",
        "    XML Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_XMLBW_RE.sub(u'A', s)\n",
        "\n",
        "\n",
        "def normalize_alef_hsb(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in a\n",
        "    Habash-Soudi-Buckwalter encoded string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_HSB_RE.sub(u'A', s)\n",
        "\n",
        "\n",
        "def normalize_alef_ar(s):\n",
        "    \"\"\"Normalize various Alef variations to plain a Alef character in an\n",
        "    Arabic string.\n",
        "\n",
        "    Args:\n",
        "        s (:obj:`str`): The string to be normalized.\n",
        "\n",
        "    Returns:\n",
        "        :obj:`str`: The normalized string.\n",
        "    \"\"\"\n",
        "\n",
        "    return _ALEF_NORMALIZE_AR_RE.sub(u'\\u0627', s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq7qrLAfWwFZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxJKFovJWwqZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVhVltkJVEuj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijGeHK41W2Mi"
      },
      "source": [
        "# Read Quran"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDwBlMT4fV8C",
        "outputId": "0277181e-8d72-471c-a035-5fdd4644a666"
      },
      "source": [
        "!pip install pyarabic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWHZS_cZZ2WH"
      },
      "source": [
        "import requests\n",
        "import pyarabic.araby as araby"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VhHypUhW3vh"
      },
      "source": [
        "link = \"https://raw.githubusercontent.com/language-ml/nlp-exploring-datasets/main/religious_text/id_text_with_orthographies.txt\"\n",
        "f = requests.get(link)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEx7sIYwXc_S"
      },
      "source": [
        "qtext = f.text\n",
        "f = \"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IQVBTYZX-E_"
      },
      "source": [
        "qtext = qtext.split(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afdCILwSX_G2"
      },
      "source": [
        "qdictionary = {}\n",
        "\n",
        "for i in qtext[:-1]:\n",
        "  parted_verse = i.split(\"\\t\")\n",
        "  \n",
        "  sura_verse_num = parted_verse[0]\n",
        "  verse = parted_verse[1]\n",
        "  qdictionary[sura_verse_num] = verse[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jAjlB2MY88H",
        "outputId": "5c55c9f4-b5b5-4c68-b0d1-660a8671eebe"
      },
      "source": [
        "key_list = list((qdictionary.keys()))\n",
        "len(key_list)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6236"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX8M1-p2Zj3-"
      },
      "source": [
        "def general_normalizer_1(sin):\n",
        "   s = normalize_unicode(sin)\n",
        "   s = normalize_alef_maksura_bw(s[:])\n",
        "   s = normalize_alef_maksura_safebw(s[:])\n",
        "   s = normalize_alef_maksura_xmlbw(s[:])\n",
        "   s = normalize_alef_maksura_hsb(s[:])\n",
        "   s = normalize_alef_maksura_ar(s[:])\n",
        "   s = normalize_teh_marbuta_bw(s[:])\n",
        "   s = normalize_teh_marbuta_safebw(s[:])\n",
        "   s = normalize_teh_marbuta_xmlbw(s[:])\n",
        "   s = normalize_teh_marbuta_hsb(s[:])\n",
        "   s = normalize_teh_marbuta_ar(s[:])\n",
        "   s = normalize_alef_bw(s[:])\n",
        "   s = normalize_alef_safebw(s[:])\n",
        "   s = normalize_alef_xmlbw(s[:])\n",
        "   s = normalize_alef_hsb(s[:])\n",
        "   s = normalize_alef_ar(s[:])\n",
        "   return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AZE9fzQ9bib9",
        "outputId": "7e9a524c-3de2-4681-ceaf-5860ee4c71a7"
      },
      "source": [
        "qdictionary[key_list[4]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'اياك نعبد واياك نستعين'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdtB9iZ8bnFk",
        "outputId": "d640890c-56dc-4747-9fe9-5a2a6b405065"
      },
      "source": [
        "pnot_changed = 0\n",
        "\n",
        "for i in range(6236):\n",
        "  sin = qdictionary[key_list[i]]\n",
        "  sout = general_normalizer_1(qdictionary[key_list[i]])\n",
        "  qdictionary[key_list[i]] = sout\n",
        "  if sin == sout: \n",
        "    pnot_changed += 1\n",
        "print(pnot_changed , 6236-pnot_changed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6236 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31tcj71pcAc7"
      },
      "source": [
        "def general_normalizer_2(sin):\n",
        "  sout = araby.strip_diacritics(sin)\n",
        "  sout = sout.replace(\"   \",\" \")\n",
        "  sout = sout.replace(\"  \",\" \")\n",
        "  sout = sout.replace(\"ي\",\"ی\")\n",
        "  return sout"
      ],
      "execution_count": 517,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jshvbt-IfQOJ",
        "outputId": "89479f94-165b-4f7d-edf6-0cd2764eb5bb"
      },
      "source": [
        "pnot_changed = 0\n",
        "for i in range(6236):\n",
        "  sin = qdictionary[key_list[i]]\n",
        "  sout = general_normalizer_2(qdictionary[key_list[i]])\n",
        "  qdictionary[key_list[i]] = sout\n",
        "  if sin == sout: \n",
        "    pnot_changed += 1\n",
        "    \n",
        "print(pnot_changed , 6236-pnot_changed)"
      ],
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500 5736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zomLqhFWfgsw",
        "outputId": "217c8f09-5c35-44a1-990d-2320cdaa9d21"
      },
      "source": [
        "for i in [1,100,1000,1435,6230]:\n",
        "  print(qdictionary[key_list[i]])\n",
        "  print(qtext[i].split(\"\\t\")[-1])\n",
        " \n",
        "  # sout = general_normalizer_2(qdictionary[key_list[i]])\n",
        "  # qdictionary[key_list[i]] = sout\n",
        "  # if sin == sout: \n",
        "    # pnot_changed += 1"
      ],
      "execution_count": 519,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "الحمد لله رب العالمین\n",
            "الْحَمْدُ لِلَّهِ رَبِّ الْعَالَمِينَ\n",
            "قل ان كانت لكم الدار الاخره عند الله خالصه من دون الناس فتمنوا الموت ان كنتم صادقین\n",
            "قُلْ إِنْ كَانَتْ لَكُمُ الدَّارُ الْآخِرَةُ عِنْدَ اللَّهِ خَالِصَةً مِنْ دُونِ النَّاسِ فَتَمَنَّوُا الْمَوْتَ إِنْ كُنْتُمْ صَادِقِينَ\n",
            "واذا صرفت ابصارهم تلقاء اصحاب النار قالوا ربنا لا تجعلنا مع القوم الظالمین\n",
            "وَإِذَا صُرِفَتْ أَبْصَارُهُمْ تِلْقَاءَ أَصْحَابِ النَّارِ قَالُوا رَبَّنَا لَا تَجْعَلْنَا مَعَ الْقَوْمِ الظَّالِمِينَ\n",
            "فان تولیتم فما سالتكم من اجر ان اجری الا علی الله وامرت ان اكون من المسلمین\n",
            "فَإِنْ تَوَلَّيْتُمْ فَمَا سَأَلْتُكُمْ مِنْ أَجْرٍ ۖ إِنْ أَجْرِيَ إِلَّا عَلَى اللَّهِ ۖ وَأُمِرْتُ أَنْ أَكُونَ مِنَ الْمُسْلِمِينَ\n",
            "قل اعوذ برب الناس\n",
            "قُلْ أَعُوذُ بِرَبِّ النَّاسِ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RBFSGCFiBo3"
      },
      "source": [
        "save normalized file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmLJA6uHgOMw"
      },
      "source": [
        "import codecs\n",
        "\n",
        "file = codecs.open(\"normalized.txt\", \"w\", \"utf-8\")\n",
        "for i in range(6236):\n",
        "  file.write(key_list[i])\n",
        "  file.write(\"\\t\")\n",
        "  file.write(qdictionary[key_list[i]])\n",
        "  file.write(\"\\n\")\n",
        "\n",
        "file.close()"
      ],
      "execution_count": 520,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdETN-4VkpUN"
      },
      "source": [
        "# phase 1\n",
        "## creating token bag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5g3kD7Th5dn"
      },
      "source": [
        "# qdictionary"
      ],
      "execution_count": 521,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poWzugaYk9k8"
      },
      "source": [
        "bi_token_bag = {}\n",
        "list_dk = list(qdictionary.keys())\n",
        "for i in range(len(qdictionary)):\n",
        "  k_name = list_dk[i]\n",
        "  verse = qdictionary[k_name]\n",
        "  \n",
        "  temp = verse.split(\" \")\n",
        "  for i in range(len(temp)-1):\n",
        "      try:\n",
        "        bi_token_bag[temp[i] + \" \" + temp[i+1]].append(k_name)\n",
        "      except:\n",
        "        bi_token_bag[temp[i] + \" \" + temp[i+1]] = [k_name]"
      ],
      "execution_count": 522,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7egCMZn_lTT7",
        "outputId": "2080da1c-78dd-4f81-a0a1-8f180b82108c"
      },
      "source": [
        "bi_token_list = list(bi_token_bag.keys())\n",
        "print(len(bi_token_list))"
      ],
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b9328qElUyz",
        "outputId": "857c1af7-bef4-49ba-c705-6badc66fc84b"
      },
      "source": [
        "for i in range(10):\n",
        "  print(bi_token_list[i] , \":::\" , bi_token_bag[bi_token_list[i]])"
      ],
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "بسم الله ::: ['1##1', '11##41', '27##30']\n",
            "الله الرحمن ::: ['1##1', '27##30']\n",
            "الرحمن الرحیم ::: ['1##1', '1##3', '2##163', '27##30', '41##2', '59##22']\n",
            "الحمد لله ::: ['1##2', '6##1', '7##43', '10##10', '14##39', '16##75', '17##111', '18##1', '23##28', '27##15', '27##59', '27##93', '29##63', '31##25', '34##1', '35##1', '35##34', '39##29', '39##74', '39##75', '40##65']\n",
            "لله رب ::: ['1##2', '6##45', '6##162', '10##10', '27##44', '37##182', '39##75', '40##65']\n",
            "رب العالمین ::: ['1##2', '5##28', '6##45', '6##162', '7##54', '7##61', '7##67', '7##104', '10##10', '10##37', '26##16', '26##23', '26##77', '26##109', '26##127', '26##145', '26##164', '26##180', '26##192', '27##8', '27##44', '28##30', '32##2', '37##182', '39##75', '40##64', '40##65', '41##9', '43##46', '45##36', '56##80', '59##16', '69##43', '81##29']\n",
            "مالك یوم ::: ['1##4']\n",
            "یوم الدین ::: ['1##4', '15##35', '26##82', '37##20', '38##78', '51##12', '56##56', '82##15', '82##17', '82##18']\n",
            "ایاك نعبد ::: ['1##5']\n",
            "نعبد وایاك ::: ['1##5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFnQtuBCqwZ4"
      },
      "source": [
        "draw hist for fun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuvMxc7oqaPg"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "counter_list = np.zeros(43685)"
      ],
      "execution_count": 525,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qe7cy-lq6cm"
      },
      "source": [
        "x = []\n",
        "for i in range(43685):\n",
        "   counter_list[i] = len( bi_token_bag[bi_token_list[i]])\n",
        "   if len( bi_token_bag[bi_token_list[i]]) > 50:\n",
        "     x.append([len( bi_token_bag[bi_token_list[i]]) , bi_token_list[i]])"
      ],
      "execution_count": 526,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MAjx9DerKTH",
        "outputId": "93e9c9c3-aa66-4b92-8071-071bb1fe241e"
      },
      "source": [
        "int(max(counter_list))"
      ],
      "execution_count": 527,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257"
            ]
          },
          "metadata": {},
          "execution_count": 527
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_ZASIk6r7Cu"
      },
      "source": [
        "x.sort()"
      ],
      "execution_count": 528,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUnvumy4sh_W",
        "outputId": "67912fb5-bd09-413a-9afa-44504abbe9f1"
      },
      "source": [
        "x[::-1]"
      ],
      "execution_count": 529,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[257, 'ان الله'],\n",
              " [184, 'الذین امنوا'],\n",
              " [176, 'فی الارض'],\n",
              " [142, 'یا ایها'],\n",
              " [134, 'الذین كفروا'],\n",
              " [133, 'السماوات والارض'],\n",
              " [92, 'من قبل'],\n",
              " [92, 'ایها الذین'],\n",
              " [89, 'من الله'],\n",
              " [87, 'كل شیء'],\n",
              " [84, 'من بعد'],\n",
              " [84, 'ان الذین'],\n",
              " [83, 'من دون'],\n",
              " [81, 'ان كنتم'],\n",
              " [72, 'علی الله'],\n",
              " [72, 'دون الله'],\n",
              " [71, 'فی السماوات'],\n",
              " [71, 'الله من'],\n",
              " [71, 'الله ان'],\n",
              " [69, 'ما فی'],\n",
              " [69, 'سبیل الله'],\n",
              " [63, 'الله لا'],\n",
              " [62, 'من یشاء'],\n",
              " [61, 'عند الله'],\n",
              " [61, 'الحیاه الدنیا'],\n",
              " [61, 'الا ان'],\n",
              " [60, 'یوم القیامه'],\n",
              " [57, 'ان فی'],\n",
              " [56, 'علی كل'],\n",
              " [53, 'وعملوا الصالحات'],\n",
              " [53, 'ما كانوا'],\n",
              " [52, 'فی ذلك'],\n",
              " [51, 'وما كان'],\n",
              " [51, 'من السماء']]"
            ]
          },
          "metadata": {},
          "execution_count": 529
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_r75BySYl1t"
      },
      "source": [
        "# phase 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93XxbJaXsjkm"
      },
      "source": [
        "# input = \"آیه را زیر لب زمزمه می‌کرد که أَمْ حَسِبْتَ أَنَّ أَصْحَابَ ٱلْكَهْفِ وَٱلرَّقِيمِ كَانُواْ مِنْ ءَايَتِنَا عَجَبًا، آیا اصحاب کهف را از عجایب آیات ما می‌پنداری؟ پرواز\"\n",
        "input = \"(علیه السلام)- فِی قَوْلِهِ تَعَالَی قُلْ هذِهِ سَبِیلِی أَدْعُوا إِلَی اللهِ عَلی بَصِیرَةٍ أَنَا وَمَنِ اتَّبَعَنِی قَالَ هِیَ وَلَایَتُنَا أَهْلَ الْبَیْتِ.\""
      ],
      "execution_count": 561,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DarRsUnmoJ5"
      },
      "source": [
        "# input = \" خخخخ ام حسبت ان اصحاب الكهف ززز\""
      ],
      "execution_count": 562,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtIPcVKxtRu9"
      },
      "source": [
        "def input_normalizer(input):\n",
        "  for i in \"?!.؟!.\":\n",
        "    input = input.replace(i , \"\")\n",
        "  normalized_in_1 = general_normalizer_1(input)\n",
        "  normalized_in_2 = general_normalizer_2(normalized_in_1)\n",
        "\n",
        "  return normalized_in_2"
      ],
      "execution_count": 563,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYNJc5uMtfOV"
      },
      "source": [
        "bad_alphabets = ['\\u200c' , 'پ' ,  'ژ' , 'چ' , 'گ']"
      ],
      "execution_count": 564,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg3ZSGjjt-qF"
      },
      "source": [
        "input = input_normalizer(input)\n",
        "inlist = input.split(\" \")\n",
        "bag_of_input = []\n",
        "for i in range(len(inlist)-1):\n",
        "  flag = True\n",
        "  for alphabet in bad_alphabets: \n",
        "    if alphabet in inlist[i] or alphabet in inlist[i+1]:\n",
        "      flag = False\n",
        "  if flag:\n",
        "    bag_of_input.append(inlist[i] + \" \" + inlist[i+1])"
      ],
      "execution_count": 565,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tixSCOm3uEGN",
        "outputId": "226b249c-3c0c-4522-e9fa-7a023d97ef25"
      },
      "source": [
        "bag_of_input"
      ],
      "execution_count": 566,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(علیه السلام)-',\n",
              " 'السلام)- فی',\n",
              " 'فی قوله',\n",
              " 'قوله تعالی',\n",
              " 'تعالی قل',\n",
              " 'قل هذه',\n",
              " 'هذه سبیلی',\n",
              " 'سبیلی ادعوا',\n",
              " 'ادعوا الی',\n",
              " 'الی الله',\n",
              " 'الله علی',\n",
              " 'علی بصیره',\n",
              " 'بصیره انا',\n",
              " 'انا ومن',\n",
              " 'ومن اتبعنی',\n",
              " 'اتبعنی قال',\n",
              " 'قال هی',\n",
              " 'هی ولایتنا',\n",
              " 'ولایتنا اهل',\n",
              " 'اهل البیت']"
            ]
          },
          "metadata": {},
          "execution_count": 566
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yBP6zWeywZB"
      },
      "source": [
        "# phase 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwft5ixSvPmz"
      },
      "source": [
        "import re"
      ],
      "execution_count": 567,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkhQfAP6y5h4"
      },
      "source": [
        "list_bi_token_bag = list(bi_token_bag.keys())\n",
        "found_list = []\n",
        "\n",
        "for biword in bag_of_input:\n",
        "  if biword in list_bi_token_bag:\n",
        "    for i in bi_token_bag[biword]:\n",
        "      found_list.append([i,biword])"
      ],
      "execution_count": 568,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6mWbgmSy66B",
        "outputId": "8d16b01f-e926-4428-a9ae-cea338d7f9c4"
      },
      "source": [
        "found_list"
      ],
      "execution_count": 569,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['12##108', 'قل هذه'],\n",
              " ['12##108', 'هذه سبیلی'],\n",
              " ['2##275', 'الی الله'],\n",
              " ['2##281', 'الی الله'],\n",
              " ['3##52', 'الی الله'],\n",
              " ['4##59', 'الی الله'],\n",
              " ['4##100', 'الی الله'],\n",
              " ['5##48', 'الی الله'],\n",
              " ['5##74', 'الی الله'],\n",
              " ['5##105', 'الی الله'],\n",
              " ['6##62', 'الی الله'],\n",
              " ['6##136', 'الی الله'],\n",
              " ['6##159', 'الی الله'],\n",
              " ['9##59', 'الی الله'],\n",
              " ['10##30', 'الی الله'],\n",
              " ['11##4', 'الی الله'],\n",
              " ['12##86', 'الی الله'],\n",
              " ['12##108', 'الی الله'],\n",
              " ['16##87', 'الی الله'],\n",
              " ['24##31', 'الی الله'],\n",
              " ['24##48', 'الی الله'],\n",
              " ['24##51', 'الی الله'],\n",
              " ['25##71', 'الی الله'],\n",
              " ['31##22', 'الی الله'],\n",
              " ['33##46', 'الی الله'],\n",
              " ['35##15', 'الی الله'],\n",
              " ['39##3', 'الی الله'],\n",
              " ['39##17', 'الی الله'],\n",
              " ['40##43', 'الی الله'],\n",
              " ['40##44', 'الی الله'],\n",
              " ['41##33', 'الی الله'],\n",
              " ['42##10', 'الی الله'],\n",
              " ['42##53', 'الی الله'],\n",
              " ['51##50', 'الی الله'],\n",
              " ['58##1', 'الی الله'],\n",
              " ['61##14', 'الی الله'],\n",
              " ['66##4', 'الی الله'],\n",
              " ['66##8', 'الی الله'],\n",
              " ['2##7', 'الله علی'],\n",
              " ['2##20', 'الله علی'],\n",
              " ['2##89', 'الله علی'],\n",
              " ['2##106', 'الله علی'],\n",
              " ['2##109', 'الله علی'],\n",
              " ['2##148', 'الله علی'],\n",
              " ['2##185', 'الله علی'],\n",
              " ['2##204', 'الله علی'],\n",
              " ['2##259', 'الله علی'],\n",
              " ['3##61', 'الله علی'],\n",
              " ['3##164', 'الله علی'],\n",
              " ['3##165', 'الله علی'],\n",
              " ['4##72', 'الله علی'],\n",
              " ['4##85', 'الله علی'],\n",
              " ['4##133', 'الله علی'],\n",
              " ['6##91', 'الله علی'],\n",
              " ['7##44', 'الله علی'],\n",
              " ['7##101', 'الله علی'],\n",
              " ['9##15', 'الله علی'],\n",
              " ['9##93', 'الله علی'],\n",
              " ['9##97', 'الله علی'],\n",
              " ['9##117', 'الله علی'],\n",
              " ['11##18', 'الله علی'],\n",
              " ['12##66', 'الله علی'],\n",
              " ['12##108', 'الله علی'],\n",
              " ['16##77', 'الله علی'],\n",
              " ['16##108', 'الله علی'],\n",
              " ['18##45', 'الله علی'],\n",
              " ['22##11', 'الله علی'],\n",
              " ['22##17', 'الله علی'],\n",
              " ['22##34', 'الله علی'],\n",
              " ['22##37', 'الله علی'],\n",
              " ['22##39', 'الله علی'],\n",
              " ['24##45', 'الله علی'],\n",
              " ['29##20', 'الله علی'],\n",
              " ['30##59', 'الله علی'],\n",
              " ['33##27', 'الله علی'],\n",
              " ['33##52', 'الله علی'],\n",
              " ['33##73', 'الله علی'],\n",
              " ['35##1', 'الله علی'],\n",
              " ['40##35', 'الله علی'],\n",
              " ['45##23', 'الله علی'],\n",
              " ['47##16', 'الله علی'],\n",
              " ['48##21', 'الله علی'],\n",
              " ['59##6', 'الله علی'],\n",
              " ['59##7', 'الله علی'],\n",
              " ['65##12', 'الله علی'],\n",
              " ['12##108', 'علی بصیره'],\n",
              " ['12##108', 'بصیره انا'],\n",
              " ['12##108', 'انا ومن'],\n",
              " ['12##108', 'ومن اتبعنی'],\n",
              " ['12##26', 'قال هی'],\n",
              " ['20##18', 'قال هی'],\n",
              " ['11##73', 'اهل البیت'],\n",
              " ['33##33', 'اهل البیت']]"
            ]
          },
          "metadata": {},
          "execution_count": 569
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC26lIGH0lJH"
      },
      "source": [
        "# found_list[1][1] , found_list[1][0]"
      ],
      "execution_count": 570,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7wEt3lcQ0xPP",
        "outputId": "2a17ab58-997c-4a78-e6bd-6d7a97cadc9b"
      },
      "source": [
        "qdictionary['12##108']"
      ],
      "execution_count": 571,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'قل هذه سبیلی ادعو الی الله علی بصیره انا ومن اتبعنی وسبحان الله وما انا من المشركین'"
            ]
          },
          "metadata": {},
          "execution_count": 571
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ_59s3P120H"
      },
      "source": [
        "def rule_maker(sentence , biword):\n",
        "  indexes = []\n",
        "  [word1 , word2] = biword.split(\" \")\n",
        " \n",
        "  sentencelist = sentence.split(\" \")\n",
        "\n",
        "  for i in range(len(sentencelist)-1):\n",
        "    if sentencelist[i] == word1 and sentencelist[i+1] == word2:\n",
        "      indexes.append(i)\n",
        "      # print(i,sentencelist[i])\n",
        "  rules = []\n",
        "  for index in indexes:\n",
        "    # print(index)\n",
        "    rule = \"(\" + biword + \")\"\n",
        "    for j in range(index-1,-1,-1):\n",
        "        # rule = \"(( \" + sentencelist[j] + \")?\"  + rule + \")\"\n",
        "        rule = \"((\" + sentencelist[j] +\" )?\" + rule + \")\"\n",
        "    for j in range(index+2,len(sentencelist)):\n",
        "        rule = \"((\"  + rule + \")\" +  \"( \" + sentencelist[j] + \")?)\"\n",
        "    # if index+2 < len(sentencelist): \n",
        "      # j=len(sentencelist)-1\n",
        "      # rule = \"((\"  + rule + \")\" +  \"(\" + sentencelist[j] + \")?)\"\n",
        "    rules.append(rule)\n",
        "  return rules"
      ],
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP2QYKvmcTbK"
      },
      "source": [
        "# sentence = input #qdictionary[found_list[1][1]] \n",
        "# biword = found_list[0][1]\n",
        "# # print(sentence)\n",
        "# # print(biword)\n",
        "# rules = rul_maker(sentence , biword)\n",
        "# # for r in rules:\n",
        "#   # print(r)\n",
        "# # print(rules)"
      ],
      "execution_count": 573,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFjd8RUbd-a-"
      },
      "source": [
        "bag_of_outputs = []\n",
        "\n",
        "for i in found_list:\n",
        "  verse = qdictionary[i[0]]\n",
        "\n",
        "  sentence = input #qdictionary[found_list[1][1]] \n",
        "  biword = i[1]\n",
        "  # print(biword )\n",
        "  rules = rule_maker(input , biword)\n",
        "  # print(len(rules), \"  *** \" , rule)\n",
        "\n",
        "  for rule in rules:\n",
        "    # print(rule)\n",
        "    subouts = re.findall(rule,verse)\n",
        "    for subout in subouts:\n",
        "      temp = \"\"\n",
        "      for sample in subout:   \n",
        "        if(len(sample) > len(temp)):\n",
        "            temp = sample[:]\n",
        "      bag_of_outputs.append([i[0],temp])\n",
        "    \n",
        "          "
      ],
      "execution_count": 593,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKj6CKoplzmf"
      },
      "source": [
        "# a = [1,4,2]\n",
        "# a.sort()\n",
        "# a"
      ],
      "execution_count": 604,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB0LrB3_l9AW"
      },
      "source": [
        "new_list = [bag_of_outputs[i]]\n",
        "bag_of_outputs.sort()\n",
        "new_list = [bag_of_outputs[0]]\n",
        "for i in range(1,len(bag_of_outputs)):\n",
        "  if bag_of_outputs[i] == new_list[-1] :\n",
        "    pass\n",
        "  elif bag_of_outputs[i][0] == new_list[-1][0]:\n",
        "    if new_list[-1][0] in bag_of_outputs[i][1]:\n",
        "      new_list[-1] = bag_of_outputs[i]\n",
        "  else:\n",
        "      new_list.append(bag_of_outputs[i])\n"
      ],
      "execution_count": 613,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbunznmIRMCD",
        "outputId": "a6c9b648-faad-4eb0-ee3d-cce8b97533ff"
      },
      "source": [
        "for i in new_list:\n",
        "  print(i)"
      ],
      "execution_count": 615,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['10##30', 'الی الله']\n",
            "['11##18', 'الله علی']\n",
            "['11##4', 'الی الله']\n",
            "['11##73', 'اهل البیت']\n",
            "['12##108', 'الی الله علی بصیره انا ومن اتبعنی']\n",
            "['12##26', 'قال هی']\n",
            "['12##66', 'الله علی']\n",
            "['12##86', 'الی الله']\n",
            "['16##108', 'الله علی']\n",
            "['16##77', 'الله علی']\n",
            "['16##87', 'الی الله']\n",
            "['18##45', 'الله علی']\n",
            "['2##106', 'الله علی']\n",
            "['2##109', 'الله علی']\n",
            "['2##148', 'الله علی']\n",
            "['2##185', 'الله علی']\n",
            "['2##20', 'الله علی']\n",
            "['2##204', 'الله علی']\n",
            "['2##259', 'الله علی']\n",
            "['2##275', 'الی الله ومن']\n",
            "['2##281', 'الی الله']\n",
            "['2##7', 'الله علی']\n",
            "['2##89', 'الله علی']\n",
            "['20##18', 'قال هی']\n",
            "['22##11', 'الله علی']\n",
            "['22##17', 'الله علی']\n",
            "['22##34', 'الله علی']\n",
            "['22##37', 'الله علی']\n",
            "['22##39', 'الله علی']\n",
            "['24##31', 'الی الله']\n",
            "['24##45', 'الله علی']\n",
            "['24##48', 'الی الله']\n",
            "['24##51', 'الی الله']\n",
            "['25##71', 'الی الله']\n",
            "['29##20', 'الله علی']\n",
            "['3##164', 'الله علی']\n",
            "['3##165', 'الله علی']\n",
            "['3##52', 'الی الله قال']\n",
            "['3##61', 'الله علی']\n",
            "['30##59', 'الله علی']\n",
            "['31##22', 'الی الله']\n",
            "['33##27', 'الله علی']\n",
            "['33##33', 'اهل البیت']\n",
            "['33##46', 'الی الله']\n",
            "['33##52', 'الله علی']\n",
            "['33##73', 'الله علی']\n",
            "['35##1', 'الله علی']\n",
            "['35##15', 'الی الله']\n",
            "['39##17', 'الی الله']\n",
            "['39##3', 'الی الله']\n",
            "['4##100', 'الی الله']\n",
            "['4##133', 'الله علی']\n",
            "['4##59', 'الی الله']\n",
            "['4##72', 'الله علی']\n",
            "['4##85', 'الله علی']\n",
            "['40##35', 'الله علی']\n",
            "['40##43', 'الی الله']\n",
            "['40##44', 'الی الله']\n",
            "['41##33', 'الی الله']\n",
            "['42##10', 'الی الله']\n",
            "['42##53', 'الی الله']\n",
            "['45##23', 'الله علی']\n",
            "['47##16', 'الله علی']\n",
            "['48##21', 'الله علی']\n",
            "['5##105', 'الی الله']\n",
            "['5##48', 'الی الله']\n",
            "['5##74', 'الی الله']\n",
            "['51##50', 'الی الله']\n",
            "['58##1', 'الی الله']\n",
            "['59##6', 'الله علی']\n",
            "['59##7', 'الله علی']\n",
            "['6##136', 'الی الله']\n",
            "['6##159', 'الی الله']\n",
            "['6##62', 'الی الله']\n",
            "['6##91', 'الله علی']\n",
            "['61##14', 'الی الله قال']\n",
            "['65##12', 'الله علی']\n",
            "['66##4', 'الی الله']\n",
            "['66##8', 'الی الله']\n",
            "['7##101', 'الله علی']\n",
            "['7##44', 'الله علی']\n",
            "['9##117', 'الله علی']\n",
            "['9##15', 'الله علی']\n",
            "['9##59', 'الی الله']\n",
            "['9##93', 'الله علی']\n",
            "['9##97', 'الله علی']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b9wOEli6vyf",
        "outputId": "ed4f646c-1a2e-4da1-eef8-f803f04ba839"
      },
      "source": [
        "\"a s\" in \"a d s d \""
      ],
      "execution_count": 612,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 612
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmeQ5kUg69NS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}